{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multidimensional Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])\n",
    "plt.rcParams['figure.figsize'] = (15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string_fb = 'mysql://{user}:{password}@{host}:{port}/{db}'.format(\n",
    "    user='student',\n",
    "    password='dwdstudent2015',\n",
    "    host='db.ipeirotis.org',\n",
    "    port=3306,\n",
    "    db='facebook')\n",
    "engine_fb = create_engine(conn_string_fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift and Log-odds: Facebook, Favorite Books, and Political views\n",
    "\n",
    "Now let's do an analysis that examines book preferences and how they correlated with political leanings.\n",
    "\n",
    "We will start by fetching the favorite books for students that declared themselves as Liberal or Conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = '''\n",
    "SELECT B.Book, P.PoliticalViews, COUNT(*) AS cnt \n",
    "FROM Profiles P JOIN FavoriteBooks B ON B.ProfileID = P.ProfileId  \n",
    "WHERE PoliticalViews IS NOT NULL AND B.Book IS NOT NULL \n",
    "      AND (PoliticalViews = 'Liberal' OR PoliticalViews = 'Conservative')\n",
    "AND B.Book IN (\n",
    "    SELECT Book \n",
    "    FROM FavoriteBooks B JOIN Profiles P ON B.ProfileID = P.ProfileId  \n",
    "    WHERE (P.PoliticalViews = 'Liberal' OR P.PoliticalViews = 'Conservative')\n",
    "    GROUP BY Book HAVING COUNT(DISTINCT P.ProfileID)>10\n",
    ")\n",
    "GROUP BY B.Book, P.PoliticalViews;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_sql(books, con=engine_fb)\n",
    "df_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_books.pivot_table(\n",
    "    index='Book', \n",
    "    columns='PoliticalViews', \n",
    "    values='cnt')\n",
    "dfp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `NaN` values for the entries where we had no users falling into that group. Since we will want to do calculations for these books as well, we will use the `fillna` command to fill these entries with a default value (in our case, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NaN entries with the value 0 \n",
    "dfp = df_books.pivot_table(\n",
    "    index='Book', \n",
    "    columns='PoliticalViews', \n",
    "    values='cnt').fillna(0)\n",
    "dfp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "We now want to normalize the entries before proceeding further. Let's take a look at the breakdown of political views in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polviews = '''\n",
    "SELECT PoliticalViews, COUNT(*) AS cnt \n",
    "FROM facebook.Profiles\n",
    "GROUP BY PoliticalViews\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polviews = pd.read_sql(polviews, con=engine_fb)\n",
    "df_polviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polviews.set_index('PoliticalViews', inplace=True)\n",
    "df_polviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberals = df_polviews.at['Liberal','cnt']\n",
    "liberals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservatives = df_polviews.at['Conservative','cnt']\n",
    "conservatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have many more conservatives than liberals, let's create a new column that calculates the **percentage** of liberal and conservative students that liked each book. We add the `+1` in the numerator to avoid division by zero later on. _As practice, try to fetch the values 936 and 6461 directly from the database, and automate the calculation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[\"Liberal_perc\"] = 100*(dfp[\"Liberal\"] +1)  / liberals\n",
    "dfp[\"Conservative_perc\"] = 100*(dfp[\"Conservative\"] +1)  / conservatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.loc['Harry Potter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift\n",
    "\n",
    "Now that we have the normalized values, we can compute the **lift** for each book. The lift is the ratio between the percentage of liberals and the percentage of convervatives. A book with `lift==1` will be equally read by both conservatives and liberals. Books that have lifts significantly higher or lower than 1, reveal preferences to be read by one side of the political spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[\"lift_liberal\"] = dfp[\"Liberal_perc\"] / dfp[\"Conservative_perc\"]\n",
    "dfp[\"lift_conservative\"] = dfp[\"Conservative_perc\"]  / dfp[\"Liberal_perc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = dfp[ ['lift_liberal', 'lift_conservative', 'Liberal_perc', 'Conservative_perc', 'Liberal', 'Conservative'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-odds\n",
    "\n",
    "One common tranformation is to take the `log` of the lift. We call this metric **log odds**. In that case, the `lift==1` corresponds to a `log_odds` of 0. Negative values indicate negative association, and positive values indicate positive association. A nice property of log-odds is that they are **additive**, which means that summing up log-odds makes (mathematical) sense, under some reasonably general conditions. (The details are beyond the scope of this course, but you can learn more in the data mining class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dfp[\"log_odds_liberal\"]      =  np.log(dfp[\"lift_liberal\"])\n",
    "dfp[\"log_odds_conservative\"] =  np.log(dfp[\"lift_conservative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp[ ['log_odds_liberal', 'log_odds_conservative', 'lift_liberal', 'lift_conservative', 'Liberal', 'Conservative'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_columns = [\"lift_liberal\", \"log_odds_liberal\", \"lift_conservative\", \"log_odds_conservative\", \"Liberal\", \"Conservative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal_books = (dfp[show_columns]\n",
    "                 .sort_values(\"lift_liberal\", ascending=False)\n",
    "                 .head(11)\n",
    "                )\n",
    "liberal_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_books = (dfp[show_columns]\n",
    "                      .sort_values(\"lift_conservative\", ascending=False)\n",
    "                      .head(11)\n",
    "                     )\n",
    "conservative_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = conservative_books.lift_conservative.plot(kind='barh', figsize=(15,5))\n",
    "plot.set_xlabel(\"Lift for Conservatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = liberal_books.lift_liberal.plot(kind='barh', figsize=(15,5))\n",
    "plot.set_xlabel(\"Lift for Liberals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "We have seen how to compute the log-odds between liberal-conservative for each book. Given this information, we can try to estimate political leanings of students. You can do this by summing the log-odds of their favorite books. \n",
    "\n",
    "Steps: \n",
    "1. Create a table with the log-odds of the books. \n",
    "2. Join the table with the log-odds with the book preferences table.\n",
    "3. Sum the log-odds score for each student.\n",
    "\n",
    "Evaluation:\n",
    "* You have students that have declared their political preferences as Liberal, Conservative, Very Liberal, Very Conservative. Examine the scores for these students, to check how well this technique works. The simplest way is to compute the average (mean) log-odds for students that fall into the different groups. Alternatively, you can try to plot the full distribution of scores.\n",
    "* Calculate a score for each student that did not declare a political view but has listed Favorite Books.\n",
    "\n",
    "Notes: \n",
    "* You can do the work in MySQL or in Pandas. If you decide to work purely in Pandas, the [`merge`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html#pandas.DataFrame.merge) command allows you to perform joins between dataframes, in way similar to SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
